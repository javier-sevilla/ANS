{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>VC03: Clustering Jerárquico Aglomerativo</h1></center>\n",
    "\n",
    "En esta práctica estudiaremos el funcionamiento y la utilización del clústering jerárquico aglomerativo.\n",
    "\n",
    "Para empezar, cargamos las librerías que vamos a necesitar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para comenzar, cargamos el conjunto de datos con el que trabajaremos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17) # Fijamos una semilla para asegurar la reproducibilidad de la práctica\n",
    "\n",
    "data_file_url = 'https://raw.githubusercontent.com/javier-sevilla/ANS/master/datasets/sinteticos/dataset_reducido.csv'\n",
    "Dx = np.array(pd.read_csv(data_file_url,header=0))\n",
    "Dx = Dx[ np.random.choice(np.arange(Dx.shape[0]), Dx.shape[0], replace=False) ,:]\n",
    "\n",
    "plt.scatter(Dx[:,0], Dx[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Con este dataset trabajaremos y estudiaremos en esta práctica las diferentes variantes del clústering aglomerativo. Para empezar, será necesario calcular la matriz de distancias, por lo que recuperamos de prácticas anteriores la función matriz_distancias.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancia_euclidiana(x, y):   \n",
    "    return np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "def matriz_distancias(X, distancia):\n",
    "    mD = np.zeros((X.shape[0],X.shape[0]))\n",
    "    for pair in it.product(np.arange(X.shape[0]), repeat=2):\n",
    "        mD[pair] = distancia(X[pair[0],:],X[pair[1],:])\n",
    "    return mD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Necesitamos una función que, dada una matriz de distancias, construya un clustering aglomerativo. Es decir, partiendo de n clústeres (uno por ejemplo de entrenamiento), se van uniendo iterativamente dos clústeres (escogidos según minimizan la distancia interclúster definida de acuerdo a cierto criterio) hasta que todos los elementos se agrupan en un único clúster final.\n",
    "\n",
    "Sabemos que el número de uniones es igual a n-1 (el número de ejemplos menos uno). En la siguiente función, vamos guardando en cada columna de la matriz mParticiones la partición en clústeres de los ejemplos: cada partición mParticiones[:,p], de longitud n, guarda el clúster al que pertenece el i-ésimo ejemplo en la posición mParticiones[i,p]. Para rellenar esa matriz, en cada paso (unión), se calcula la matriz de distancia entre todos los pares de clústeres usando el criterio elegido. Después, simplemente se trata de asignar todos los elementos de los clústeres elegidos a un mismo grupo. Este procedimiento iterativo se repite hasta que sólo queda un clúster en el paso final:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_aglomerativo(mD, criterio):\n",
    "    mParticiones = np.zeros(mD.shape[0]**2, dtype = np.int8)\n",
    "    mParticiones.shape = (mD.shape[0], mD.shape[0])\n",
    "    mParticiones[:,21] = np.arange(22)\n",
    "\n",
    "    # Recorremos de manera decreciente \n",
    "    # ya que sabemos que el número de uniones es exactamente de n-1\n",
    "\n",
    "    a = np.array(range(mParticiones.shape[1]-1))\n",
    "    for n in a[::-1]:\n",
    "        mParticiones[:,n] = mParticiones[:,n+1]\n",
    "\n",
    "        clust_actuales = np.unique(mParticiones[:,n])\n",
    "        mDC = criterio(mD, clust_actuales, mParticiones[:,n])\n",
    "\n",
    "        ind = np.unravel_index(np.argmin(mDC, axis=None), mDC.shape)\n",
    "        mParticiones[mParticiones[:,n]==clust_actuales[ind[1]],n] = clust_actuales[ind[0]]\n",
    "\n",
    "    return mParticiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En la parte teórica estudiamos tres criterios diferentes (medidas de disimilitud interclúster). El primero que vamos a ver es el de la disimilitud media: dado cierto par de clústeres, se calcula la media de la disimilitud-distancia entre todos los pares de ejemplos (uno ejemplo de cada clúster).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disimilitud_media(mD, clust_actuales, particion):\n",
    "    mDC = np.zeros(clust_actuales.size**2)\n",
    "    mDC.shape = (clust_actuales.size,clust_actuales.size)\n",
    "    for n1 in np.arange(clust_actuales.size):\n",
    "        exC1 = np.where(particion==clust_actuales[n1])[0]\n",
    "        for n2 in np.arange(clust_actuales.size):\n",
    "            exC2 = np.where(particion==clust_actuales[n2])[0]\n",
    "            mDC[n1,n2] = np.mean(mD[np.ix_(exC1,exC2)])\n",
    "    # Rellenamos la matriz diagonal para evitar que se proponga\n",
    "    # la unión de un clúster consigo mismo\n",
    "    np.fill_diagonal(mDC, np.max(mDC)*2)\n",
    "    return mDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Con pocos cambios, se puede definir la disimilitud interclúster mínima: dado cierto par de clústeres, la distancia entre ambos es igual a la distancia mínima de cualquier par de ejemplos (uno ejemplo de cada clúster).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disimilitud_minima(mD, clust_actuales, particion):\n",
    "    mDC = np.zeros(clust_actuales.size**2)\n",
    "    mDC.shape = (clust_actuales.size,clust_actuales.size)\n",
    "    for n1 in np.arange(clust_actuales.size):\n",
    "        exC1 = np.where(particion==clust_actuales[n1])[0]\n",
    "        for n2 in np.arange(clust_actuales.size):\n",
    "            exC2 = np.where(particion==clust_actuales[n2])[0]\n",
    "            mDC[n1,n2] = np.min(mD[np.ix_(exC1,exC2)])\n",
    "    # Rellenamos la matriz diagonal para evitar que se proponga\n",
    "    # la unión de un clúster consigo mismo\n",
    "    np.fill_diagonal(mDC, np.max(mDC)*2)\n",
    "    return mDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "De manera equivalente, se define la disimilitud interclúster máxima: dado cierto par de clústeres, la distancia entre ambos es igual a la distancia máxima de cualquier par de ejemplos (uno ejemplo de cada clúster).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def disimilitud_maxima(mD, clust_actuales, particion):\n",
    "    mDC = np.zeros(clust_actuales.size**2)\n",
    "    mDC.shape = (clust_actuales.size,clust_actuales.size)\n",
    "    for n1 in np.arange(clust_actuales.size):\n",
    "        exC1 = np.where(particion==clust_actuales[n1])[0]\n",
    "        for n2 in np.arange(clust_actuales.size):\n",
    "            exC2 = np.where(particion==clust_actuales[n2])[0]\n",
    "            mDC[n1,n2] = np.max(mD[np.ix_(exC1,exC2)])\n",
    "    # Rellenamos la matriz diagonal para evitar que se proponga\n",
    "    # la unión de un clúster consigo mismo\n",
    "    np.fill_diagonal(mDC, np.max(mDC)*2)\n",
    "    return mDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finalmente, incluimos una serie de funciones que nos van a permitir visualizar los resultados:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra los ejemplos coloreados según su pertenencia a los clústeres\n",
    "# K indica el número de clústeres a mostrar a partir de la jerarquía\n",
    "def plot_particion_K(Dx, mParticiones,K):\n",
    "    cmap = get_cmap('tab20')\n",
    "    vals = np.arange(Dx.shape[0]+2)/(Dx.shape[0]+2)\n",
    "    rgba = cmap(vals[np.arange(Dx.shape[0])+1])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.scatter(Dx[:,0],Dx[:,1], c=rgba[mParticiones[:,K-1],:])\n",
    "\n",
    "# Muestra el plot de todas las particiones posibles de la jerarquía\n",
    "def plot_particiones(Dx, mParticiones):\n",
    "    for k in np.arange(mParticiones.shape[1]):\n",
    "        plot_particion_K(Dx, mParticiones,k+1)\n",
    "\n",
    "# Muestra el dendrograma de la jerarquía\n",
    "def plot_dendrograma_de_mparticiones(mD, mParticiones):\n",
    "    nPasos = mD.shape[0]-1\n",
    "    distancias = np.zeros(nPasos)\n",
    "    tamanyos = np.zeros(nPasos)\n",
    "    uniones = np.zeros(2*nPasos,dtype=np.int8)\n",
    "    uniones.shape=(nPasos,2)\n",
    "\n",
    "    mNParticiones = mParticiones.copy()\n",
    "    for n in np.arange(mNParticiones.shape[0]):\n",
    "        valor = mParticiones[n,mNParticiones.shape[1]-1]\n",
    "        mNParticiones[mParticiones==valor] = n\n",
    "\n",
    "    k = 0\n",
    "    aux = np.array(range(mNParticiones.shape[1]-1))\n",
    "    for n in aux[::-1]:\n",
    "        # cual es el diferente?\n",
    "        prim_diferencia = np.where(mParticiones[:,n]!=mParticiones[:,n+1])[0][0]\n",
    "        submatriz = mNParticiones[:,:n+1]\n",
    "        submatriz[submatriz==mNParticiones[prim_diferencia,n]] = mNParticiones.shape[1]+k\n",
    "        mNParticiones[:,:n+1] = submatriz\n",
    "        uniones[k,:] = np.unique(mNParticiones[mNParticiones[:,n]==mNParticiones.shape[1]+k,n+1])\n",
    "        tamanyos[k] = np.sum(mNParticiones[:,n]==mNParticiones.shape[1]+k)\n",
    "\n",
    "        vs = mNParticiones[:,n+1]\n",
    "        distancias[k] = 1 / (2 * tamanyos[k]) * (    \n",
    "            np.sum(mD[ np.ix_(np.where(vs == uniones[k,0])[0],\n",
    "                              np.where(vs == uniones[k,1])[0])])+\n",
    "            np.sum(mD[ np.ix_(np.where(vs == uniones[k,1])[0],\n",
    "                              np.where(vs == uniones[k,0])[0])]))\n",
    "        k += 1\n",
    "\n",
    "    distancias = np.arange(uniones.shape[0])\n",
    "    # Creamos la matriz de enlaces que necesita el método dendrogram de scipy\n",
    "    mEnlaces = np.column_stack([uniones, distancias, tamanyos]).astype(float)\n",
    "\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.title('Dendrograma de Clustering Jerárquico')\n",
    "    plt.xlabel('Índice del caso')\n",
    "    plt.ylabel('Distancia')\n",
    "    dendrogram(mEnlaces)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ahora ya estamos en disposición de realizar el clustering jerárquico aglomerativo. Empezaremos por calcular la matriz de distancias y, por este orden, calcularemos y mostraremos el dendrograma de los diferentes agrupamientos obtenidos de usar el criterio de disimilitud mínima, máxima y media. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mD = matriz_distancias(Dx, distancia_euclidiana)\n",
    "\n",
    "mParticiones = clustering_aglomerativo(mD, disimilitud_minima)\n",
    "plot_dendrograma_de_mparticiones(mD,mParticiones)\n",
    "\n",
    "mParticiones = clustering_aglomerativo(mD, disimilitud_maxima)\n",
    "plot_dendrograma_de_mparticiones(mD,mParticiones)\n",
    "\n",
    "mParticiones = clustering_aglomerativo(mD, disimilitud_media)\n",
    "plot_dendrograma_de_mparticiones(mD,mParticiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La función plot_particiones permite observar cómo son las diferentes particiones (niveles del clustering jerárquico) mostrando el dataset original con la asignación a clústeres descrita mediante colores: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_particiones(Dx, mParticiones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El clustering jerárquico devuelve un espectro de agrupamientos. Muchas veces, es necesario seleccionar una única partición. Dada la matriz mParticiones, esto equivalente a quedarse con una de las columnas. Si queremos seleccionar una partición donde hayan K clústeres, debemos seleccionar la columna K-1. Así, podemos calcular el valor de una métrica de evaluación cualquiera. En este caso, usamos las métricas de ancho de silueta y de Calinski Harabaz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score,calinski_harabaz_score\n",
    "\n",
    "K = 4\n",
    "partToEval = mParticiones[:,K-1]\n",
    "\n",
    "print('La medida de Silueta con K =',K,'es',silhouette_score(Dx, #### TU CODIGO AQUI ####),\n",
    "      ' (** ESTE ES EL RESULTADO A INCLUIR EN EL CAMPUS**)')\n",
    "print('La medida de Calinski Harabaz con K =',K,'es',calinski_harabaz_score(Dx, #### TU CODIGO AQUI ####))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Podríamos incluso dibujar de manera sencilla la figura del codo recorriendo todas las columnas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsilueta = np.zeros(mParticiones.shape[1])\n",
    "rch = np.zeros(mParticiones.shape[1])\n",
    "for K in np.arange(1,mParticiones.shape[1]-1):\n",
    "    rsilueta[K] = silhouette_score(Dx, mParticiones[:,K])\n",
    "    rch[K] = calinski_harabaz_score(Dx, mParticiones[:,K])\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax[0].plot(np.arange(1,mParticiones.shape[1]-1), rsilueta[np.arange(1,mParticiones.shape[1]-1)],\n",
    "           linestyle='-', marker='o')\n",
    "ax[0].set_xlabel(\"Número de clústeres\")\n",
    "ax[0].set_ylabel(\"Medida de ancho de silueta\")\n",
    "\n",
    "ax[1].plot(np.arange(1,mParticiones.shape[1]-1), rch[np.arange(1,mParticiones.shape[1]-1)],\n",
    "           linestyle='-', marker='o')\n",
    "ax[1].set_xlabel(\"Número de clústeres\")\n",
    "ax[1].set_ylabel(\"Medida de Calinski Harabaz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>Implementaciones en librerías de Python</h2>\n",
    "\n",
    "La librería ScikitLearn ya implementa el algoritmo de clustering jerárquico aglomerativo. \n",
    "\n",
    "Están implementados (parámetro linkage) los criterios estudiados en teoría (disimilitud mínima : 'single'; máxima: 'complete'; y media: 'average') y muchos más.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "modelo = AgglomerativeClustering(linkage=\"single\")\n",
    "modelo = modelo.fit(Dx)\n",
    "\n",
    "modelo = AgglomerativeClustering(linkage=\"complete\")\n",
    "modelo = modelo.fit(Dx)\n",
    "\n",
    "modelo = AgglomerativeClustering(linkage=\"average\")\n",
    "modelo = modelo.fit(Dx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " En cambio, para mostrar el dendrograma, tenemos que usar la library scipy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creamos la matriz de enlaces que necesita el método dendrogram de scipy\n",
    "uniones = modelo.children_\n",
    "# Las distancias y los tamaños, en esta ocasión, los asignamos de manera \n",
    "# inocua para no alterar el resultado (no disponemos de la información completa)\n",
    "distancias = np.arange(uniones.shape[0])\n",
    "tamanyos = np.arange(2, uniones.shape[0]+2)\n",
    "mEnlaces = np.column_stack([uniones, distancias, tamanyos]).astype(float)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Dendrograma de Clustering Jerárquico')\n",
    "plt.xlabel('Índice del caso')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(mEnlaces)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Probablemente, la librería más completa para hacer clustering jerárquico aglomerativo es scipy. La función linkage es la encargada de hacer el agrupamiento jerárquico. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, fcluster, cut_tree\n",
    "\n",
    "modelo = linkage(Dx, 'single')   # disimilitud mínima\n",
    "modelo = linkage(Dx, 'complete') # disimilitud máxima\n",
    "modelo = linkage(Dx, 'average')  # disimilitud media\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Dendrograma de Clustering Jerárquico')\n",
    "plt.xlabel('Índice del caso')\n",
    "plt.ylabel('Distancia')\n",
    "dendrogram(modelo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La función cut_tree permite obtener una partición concreta dado un número de clústeres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo, n_clusters=4).flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Con la siguiente función dibujaremos los resultados del clustering (fijado un K) usando diferentes criterios de unión. Podemos usar diferentes datasets de ejemplo (ver aquellos que tiene 2 dimensiones en:\n",
    "https://github.com/javier-sevilla/ANS/tree/master/datasets\n",
    "\n",
    "Podemos hacer unas pruebas para ganar algunas intuiciones sobre cuál es la mejor estrategia según el tipo de datos...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_varios(Dx,Dy,K):\n",
    "    fig, ax = plt.subplots(1,4, figsize=(20,5))\n",
    "    ax[0].scatter(Dx[:,0], Dx[:,1], c=Dy)\n",
    "    ax[0].set_title('Datos originales')\n",
    "\n",
    "    modelo = linkage(Dx, 'single')\n",
    "    ax[1].scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo, n_clusters = K).flatten())\n",
    "    ax[1].set_title('Disimilitud mínima')\n",
    "    \n",
    "    modelo = linkage(Dx, 'complete')\n",
    "    ax[2].scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo, n_clusters = K).flatten())\n",
    "    ax[2].set_title('Disimilitud máxima')\n",
    "    \n",
    "    modelo = linkage(Dx, 'average')\n",
    "    ax[3].scatter(Dx[:,0], Dx[:,1], c=cut_tree(modelo, n_clusters = K).flatten())\n",
    "    ax[3].set_title('Disimilitud media')\n",
    "\n",
    "data_file_url = 'https://raw.githubusercontent.com/javier-sevilla/ANS/master/datasets/sinteticos/dataset_circulos_concentricos.csv'\n",
    "D = np.array(pd.read_csv(data_file_url,header=0))\n",
    "D = D[ np.random.choice(np.arange(D.shape[0]), D.shape[0], replace=False) ,:]\n",
    "Dx = D[:,0:2]\n",
    "Dy = D[:,2]\n",
    "\n",
    "plot_varios(Dx,Dy,2)\n",
    "\n",
    "\n",
    "data_file_url = 'https://raw.githubusercontent.com/javier-sevilla/ANS/master/datasets/sinteticos/dataset_dos_remolinos.csv'\n",
    "D = np.array(pd.read_csv(data_file_url,header=0))\n",
    "D = D[ np.random.choice(np.arange(D.shape[0]), D.shape[0], replace=False) ,:]\n",
    "Dx = D[:,0:2]\n",
    "Dy = D[:,2]\n",
    "\n",
    "plot_varios(Dx,Dy,2)\n",
    "\n",
    "\n",
    "data_file_url = 'https://raw.githubusercontent.com/javier-sevilla/ANS/master/datasets/sinteticos/dataset_cuatro_diferente_medida.csv'\n",
    "D = np.array(pd.read_csv(data_file_url,header=0))\n",
    "D = D[ np.random.choice(np.arange(D.shape[0]), D.shape[0], replace=False) ,:]\n",
    "Dx = D[:,0:2]\n",
    "Dy = D[:,2]\n",
    "\n",
    "plot_varios(Dx,Dy,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
