{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>VC02: K-means</h1></center>\n",
    "\n",
    "En esta práctica estudiaremos el funcionamiento y la utilización del popular algoritmo de clustering K-means.\n",
    "\n",
    "Para empezar, cargamos las librerías que vamos a necesitar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cargamos el dataset con el que vamos a trabajar:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17) # Fijamos una semilla para asegurar la reproducibilidad de la práctica\n",
    "\n",
    "data_file_url = 'https://raw.githubusercontent.com/javier-sevilla/ANS/master/datasets/sinteticos/dataset_cuatro_diferente_densidad.csv'\n",
    "D = np.array(pd.read_csv(data_file_url,header=0))\n",
    "D = D[ np.random.choice(np.arange(D.shape[0]), D.shape[0], replace=False) ,:]\n",
    "Dx = D[:,0:2]\n",
    "Dy = D[:,2]\n",
    "print('El dataset cargado tiene',Dy.size,'instancias.')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1], c=Dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El algoritmo K-means tiene un único parámetro: el número de clústeres (K). Una vez fijado este valor, el primer paso consiste en elegir unos centros iniciales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos un número de clústeres a buscar\n",
    "K = 3\n",
    "\n",
    "cDx = np.zeros(K*Dx.shape[1])\n",
    "cDx.shape = (K,Dx.shape[1])\n",
    "\n",
    "def random_sample_float(n, mi, ma):\n",
    "    return (ma - mi) * np.random.random_sample(n) + mi\n",
    "\n",
    "for d in np.arange(Dx.shape[1]):\n",
    "    cDx[:,d] = random_sample_float(K, np.min(Dx[:,d]), np.max(Dx[:,d]))\n",
    "\n",
    "print('Los centros iniciales elegidos aleatoriamente son:')\n",
    "print(cDx)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1])\n",
    "ax.scatter(cDx[:,0],cDx[:,1], marker='*', s=200, c='g')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la distancia euclidiana de una instancia x \n",
    "# con respecto a un grupo de instancias C\n",
    "# Esta distancia habra que usarla para saber cual es el centro más cercano a cada instancia\n",
    "# De forma que x será un elemento de los datos y C un conjunto de centros, de esta forma\n",
    "# sabremos que elemento de C es el más cercano a x\n",
    "def distancia_euclidiana_grupo(x, C):   \n",
    "    return np.sqrt(np.sum(np.power(C-x,2),axis=1))\n",
    "\n",
    "# Preparamos el vector donde guardamos la asignación de cada elemento \n",
    "# a un clúster (1,...,K)\n",
    "Dyp = np.zeros(Dx.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1])\n",
    "ax.scatter(cDx[:,0],cDx[:,1], marker='*', s=200, c='g')\n",
    "\n",
    "# Flag de convergencia\n",
    "iterando = True\n",
    "\n",
    "while iterando:\n",
    "\n",
    "    # Vector auxiliar para guardar los centros de la iteración pasada\n",
    "    # necesarios para identificar la convergencia\n",
    "    cDx_ant = cDx.copy()\n",
    "\n",
    "    # Buscamos el centro más cercano a cada instancia y la asignamos a ese clúster\n",
    "    # Usando la función distancia_euclidiana_grupo sabemos que centro es el que está más cerca \n",
    "    # de cada dato y almacenamos en pred_y aquellos datos que están más cerca del centro \n",
    "    # De esta forma Dyp tendra en cada índice los elementos de los clusters asociados a cada centro.\n",
    "    for i in np.arange(Dx.shape[0]):\n",
    "        pred_y = #### TU CODIGO AQUI ####\n",
    "        Dyp[i] = pred_y\n",
    "\n",
    "    # Calcular los nuevos centros\n",
    "    # Dejaremos en cDX los nuevos centros, que será el promedio de todos los datos de cada cluster\n",
    "    # para cada variable (en nuestro caso para x y para y), que es la medida que minimiza la distancia\n",
    "    for k in range(K):\n",
    "        cDx[k,:] = #### TU CODIGO AQUI ####\n",
    "\n",
    "    for k in np.arange(K):\n",
    "        ax.plot( [cDx_ant[k,0], cDx[k,0]],[cDx_ant[k,1], cDx[k,1]], linestyle='-', marker='*', c='y')\n",
    "    \n",
    "    iterando = (np.absolute(np.sum(cDx-cDx_ant)) > 0.00001)\n",
    "\n",
    "ax.scatter(cDx[:,0],cDx[:,1], marker='*', s=200, c='r')\n",
    "\n",
    "# Ver asignaciones finales\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1], c=Dyp)\n",
    "ax.scatter(cDx[:,0],cDx[:,1], marker='*', s=200, c='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aquí hay que pegar las funciones del notebooks de evaluación de la VC1 \n",
    "# (matriz_confusion, medida_error, medida_pureza,medida_f1)\n",
    "\n",
    "#### TU CODIGO AQUI ####\n",
    "\n",
    "mC = matriz_confusion(Dy,Dyp)\n",
    "\n",
    "print(mC)\n",
    "print('El valor del error cometido es = ', medida_error(mC))\n",
    "print('La pureza del agrupamiento obtenido es = ', medida_pureza(mC), ' (** ESTE ES EL RESULTADO A INCLUIR EN EL CAMPUS**)')\n",
    "print('El valor F1 es = ', medida_f1(mC))\n",
    "\n",
    "\n",
    "## Las soluciones son:\n",
    "## El valor del error cometido es =  0.002501250625312701\n",
    "## La pureza del agrupamiento obtenido es un valor del intervalo ]0.8, 1.0[ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>Implementaciones en librerías de Python</h2>\n",
    "\n",
    "La librería ScikitLearn ya implementa el algoritmo K-means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Se inicializa KMeans con el número de clústeres a buscar\n",
    "modelo = KMeans(n_clusters=2)\n",
    "# Se aprende el \n",
    "modelo = modelo.fit(Dx)\n",
    "# Predicting the clusters\n",
    "Dyp_sk = modelo.predict(Dx)\n",
    "# Obtener los centros de los clústeres\n",
    "cDx_sk = modelo.cluster_centers_\n",
    "\n",
    "# Comparing with scikit-learn centroids\n",
    "print(\"Centros encontrados por...\")\n",
    "print(\"el método programado\")\n",
    "#print(cDx)\n",
    "print(\"el método de Sci-kit Learn\")\n",
    "print(cDx_sk)\n",
    "\n",
    "\n",
    "mC_sk = matriz_confusion(Dy,Dyp_sk)\n",
    "\n",
    "print('Matriz de confusión:')\n",
    "print(mC_sk)\n",
    "print('El valor del error cometido es = ', medida_error(mC_sk))\n",
    "print('La pureza del agrupamiento obtenido es = ', medida_pureza(mC_sk))\n",
    "print('El valor F1 es = ', medida_f1(mC_sk))\n",
    "\n",
    "# Ver asignaciones finales\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1], c=Dyp_sk)\n",
    "ax.scatter(cDx_sk[:,0],cDx_sk[:,1], marker='*', s=200, c='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>K-mediods</h2>\n",
    "\n",
    "Hay ocasiones en que los centros no se pueden calcular. Esto pasa habitualmente cuando los datos son heterogeneos (una mezcla de variables continuas y categóricas). El algoritmo se plantea de manera equivalente a K-means, pero la selección de centros se realiza sobre el conjunto de datos de entrenamiento. Sólo con el objetivo de poder visualizar los resultados, usaremos un conjunto de datos continuo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(17) # Fijamos una semilla para asegurar la reproducibilidad de la práctica\n",
    "\n",
    "data_file_url = 'https://raw.githubusercontent.com/javier-sevilla/ANS/master/datasets/sinteticos/dataset_cuatro_separables_peque.csv'\n",
    "D = np.array(pd.read_csv(data_file_url,header=0))\n",
    "D = D[ np.random.choice(np.arange(D.shape[0]), D.shape[0], replace=False) ,:]\n",
    "Dx = D[:,0:2]\n",
    "Dy = D[:,2]\n",
    "print('El dataset cargado tiene',Dy.size,'instancias.')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1], c=Dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos un número de clústeres a buscar\n",
    "K = 3\n",
    "\n",
    "# Elegimos los centros iniciales entre el conjunto de datos\n",
    "cDx = Dx[np.random.choice(Dx.shape[0], K, replace=False),:]\n",
    "\n",
    "print('Los centros iniciales elegidos aleatoriamente son:')\n",
    "print(cDx)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1])\n",
    "ax.scatter(cDx[:,0],cDx[:,1], marker='*', s=200, c='g')\n",
    "\n",
    "# Definimos la distancia euclidiana de una instancia x \n",
    "# con respecto a un grupo de instancias C\n",
    "def distancia_euclidiana_grupo(x, C):   \n",
    "    return np.sqrt(np.sum(np.power(C-x,2),axis=1))\n",
    "\n",
    "def distancia_euclidiana(x, y):   \n",
    "    return np.sqrt(np.sum((x-y)**2))\n",
    "\n",
    "def matriz_distancias(X, distancia):\n",
    "    mD = np.zeros((X.shape[0],X.shape[0]))\n",
    "    for pair in it.product(np.arange(X.shape[0]), repeat=2):\n",
    "        mD[pair] = distancia(X[pair[0],:],X[pair[1],:])\n",
    "    return mD\n",
    "\n",
    "# Preparamos el vector donde guardamos la asignación de cada elemento \n",
    "# a un clúster (1,...,K)\n",
    "Dyp = np.zeros(Dx.shape[0])\n",
    "\n",
    "# Flag de convergencia\n",
    "iterando = True\n",
    "\n",
    "while iterando:\n",
    "\n",
    "    # Vector auxiliar para guardar los centros de la iteración pasada\n",
    "    # necesarios para identificar la convergencia\n",
    "    cDx_ant = cDx.copy()\n",
    "\n",
    "    # Buscamos el centro más cercano a cada instancia y la asignamos a ese clúster\n",
    "    for i in np.arange(Dx.shape[0]):\n",
    "        pred_y = #### TU CODIGO AQUI ####\n",
    "        Dyp[i] = pred_y\n",
    "\n",
    "    # Calcular los nuevos centros\n",
    "    for k in range(K):\n",
    "        mat = matriz_distancias(Dx[Dyp==k,:],distancia_euclidiana)\n",
    "        ic = np.where(Dyp==k)[0][np.argmin(#### TU CODIGO AQUI ####)]\n",
    "        cDx[k,:] = Dx[ic,:]\n",
    "\n",
    "    # Se muestra el desplazamiento de los centroides\n",
    "    for k in np.arange(K):\n",
    "        ax.plot( [cDx_ant[k,0], cDx[k,0]],[cDx_ant[k,1], cDx[k,1]], linestyle='-', marker='*', c='y')\n",
    "    \n",
    "    iterando = (np.absolute(np.sum(cDx-cDx_ant)) > 0.00001)\n",
    "\n",
    "# Se muestran los centroides finales\n",
    "ax.scatter(cDx[:,0],cDx[:,1], marker='*', s=200, c='r')\n",
    "\n",
    "# Ver asignaciones finales\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.scatter(Dx[:,0],Dx[:,1], c=Dyp)\n",
    "ax.scatter(cDx[:,0],cDx[:,1], marker='*', s=200, c='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>Elegir el mejor valor de K</h2>\n",
    "\n",
    "Para elegir el mejor valor de K se suele usar la técnica del codo. Ésta consiste en probar diferentes valores de K y evaluar el agrupamientos según alguna medida de evaluación intrínseca (ya que se supone que no se conoce la verdad básica). En este ejemplo, se usan dos medidas diferentes: la medida de Silueta y la R cuadrado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def medida_R_cuadrado(X, Xyp, cXs):\n",
    "    #### TU CODIGO AQUI ####\n",
    "\n",
    "rsilueta = np.zeros(9)\n",
    "rrsquare = np.zeros(9)\n",
    "for k in np.arange(2,11):\n",
    "    modelo = KMeans(n_clusters=k)\n",
    "    modelo = modelo.fit(Dx)\n",
    "    Dyp_sk = modelo.predict(Dx)\n",
    "    cDx_sk = modelo.cluster_centers_\n",
    "    rsilueta[k-2] = silhouette_score(Dx, Dyp_sk)\n",
    "    rrsquare[k-2]  = medida_R_cuadrado(Dx, Dyp_sk, cDx_sk)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax[0].plot( np.arange(2,11),rsilueta, linestyle='-', marker='o')\n",
    "ax[0].set_xlabel(\"Número de clústeres\")\n",
    "ax[0].set_ylabel(\"Medida de ancho de silueta\")\n",
    "\n",
    "ax[1].plot( np.arange(2,11),rrsquare, linestyle='-', marker='o')\n",
    "ax[1].set_xlabel(\"Número de clústeres\")\n",
    "ax[1].set_ylabel(\"Medida de R cuadrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Se observa que el punto con mayor puntuación es el K=4 en el caso de ancho de silueta. Con esto, podría ser suficiente. Sin embargo, si nos fijamos en la medida R cuadrado, se observa un marcado cambio de tendencia también en K=4. Este cambio es conocido como el codo. La práctica recomendada de este procedimiento indica que se debe seleccionar el punto donde se produzca el cambio de tendencia (el codo). \n",
    "\n",
    "Así, no cabe duda de que el mejor valor de K posible es 4, de acuerdo a ambas medidas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>Crea tus propios datasets de ejemplo</h2>\n",
    "\n",
    "Python implementa la función make_blobs, que permite generar conjuntos de datos de manera sencilla especificando simplemente el número de ejemplos (n_samples), el número de dimensiones (n_features) y el número de clústeres (centers):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataset con 3 dimensiones y 4 clústeres\n",
    "Dx, Dy = make_blobs(n_samples=800, n_features=3, centers=4)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(Dx[:, 0], Dx[:, 1], Dx[:, 2], c=Dy)\n",
    "ax.set_title(\"Clústeres y asignaciones reales\")\n",
    "\n",
    "modelo = KMeans(n_clusters=3)\n",
    "modelo = modelo.fit(Dx)\n",
    "Dyp_sk = modelo.predict(Dx)\n",
    "cDx_sk = modelo.cluster_centers_\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(Dx[:, 0], Dx[:, 1], Dx[:, 2], c=Dyp_sk)\n",
    "ax.scatter(cDx_sk[:, 0], cDx_sk[:, 1], cDx_sk[:, 2], marker='*', c='#050505', s=1000)\n",
    "ax.set_title(\"Clústeres y asignaciones predichos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
